{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e293186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API\"] = os.getenv(\"GROQ_API\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "468c9ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7ad450820770>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7ad4508223c0>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model = \"Gemma2-9b-It\" , api_key=os.getenv(\"GROQ_API\")) \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43825bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As an AI assistant, I can help you with a variety of tasks, such as:\\n\\n* **Generating creative content:** I can write stories, poems, articles, and even code.\\n* **Answering questions:** I have access to a vast store of knowledge and can answer your questions on a wide range of topics.\\n* **Summarizing text:** I can condense large amounts of text into shorter, more manageable summaries.\\n* **Translating languages:** I can translate text between multiple languages.\\n* **Providing conversation:** I can engage in natural and meaningful conversations on a variety of topics.\\n\\nWhat can I do for you today?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 134, 'prompt_tokens': 18, 'total_tokens': 152, 'completion_time': 0.243636364, 'prompt_time': 0.00125165, 'queue_time': 0.189028675, 'total_time': 0.244888014}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--00c36e25-4e54-49f7-be9e-82e5fb4c5bfe-0', usage_metadata={'input_tokens': 18, 'output_tokens': 134, 'total_tokens': 152})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hello, how can I assist you today?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ed855a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You told me your name is Mahdi and that you are an AI engineer!  üòÑ \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 47, 'total_tokens': 80, 'completion_time': 0.06, 'prompt_time': 0.001641379, 'queue_time': 0.188437004, 'total_time': 0.061641379}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--ea657ede-80ab-4882-b35b-8680c4f383c5-0', usage_metadata={'input_tokens': 47, 'output_tokens': 33, 'total_tokens': 80})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#basic example of history\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hello, i am mahdi and iam ai eng\"),\n",
    "        AIMessage(content=\"Hello ! its nice to meet you.\"),\n",
    "        HumanMessage(content=\"what is my name? and what i do?\")\n",
    "    ]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b64aed",
   "metadata": {},
   "source": [
    "### message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c871c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory \n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a0827bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1317fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\": \"user_session_1\"}}  # the session information \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3ee4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resposne = with_message_history.invoke(\n",
    "\n",
    "        [HumanMessage(content=\"Hello, i am mahdi and iam ai eng\")] ,\n",
    "        config=config\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2611db8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Mahdi! It's nice to meet you. \\n\\nBeing an AI engineer is exciting! What kind of projects are you working on?  \\n\\nI'm eager to learn more about your work in the field of AI. üòä  \\n\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposne.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83ec10b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'd be happy to use it! üòä\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = {\"configurable\":{\"session_id\": \"user_session_2\"}}  # the session information \n",
    "response = with_message_history.invoke(\n",
    "\n",
    "        [HumanMessage(content=\"Hello, what is my name?\")] ,\n",
    "        config=config2\n",
    "\n",
    ")\n",
    "response.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b14a25f",
   "metadata": {},
   "source": [
    "### Adding prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba398606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate , MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a602c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"system\", \"You are a helpful assistant.\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46b10f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e8370b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Mahdi! üëã \\n\\nIt's nice to meet you. How can I help you today? üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 21, 'total_tokens': 49, 'completion_time': 0.050909091, 'prompt_time': 0.00133866, 'queue_time': 0.18845393, 'total_time': 0.052247751}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--5f7302e9-ec70-4553-91b7-7b228ec74a4b-0', usage_metadata={'input_tokens': 21, 'output_tokens': 28, 'total_tokens': 49})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hello, i am mahdi\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53c84193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Mahdi, it's nice to meet you! \\n\\nHow can I be helpful today? üòÑ  \\n\\n\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
    "\n",
    "config = {\"configurable\":{\"session_id\": \"user_session_3\"}}  # the session information\n",
    "response = with_message_history.invoke([HumanMessage(content=\"Hello, my name is mahdi\")], config=config)\n",
    "response.content    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bfcc37c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## more complexity\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"system\", \"You are a helpful assistant , answer the following in this {language}\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9c1cfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¬°Hola Mahdi! üëã  \\n\\n¬øC√≥mo est√°s?  üòä \\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\":[HumanMessage(content=\"Hello, i am mahdi\")] , \"language\": \"spainish\"})\n",
    "response.content    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d69ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history= RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key= \"messages\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eeaab970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Bonjour Mahdi !  üòä \\n\\nEnchant√©(e) de te rencontrer !  \\n\\nComment puis-je vous aider aujourd'hui ? \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 28, 'total_tokens': 61, 'completion_time': 0.06, 'prompt_time': 0.001406289, 'queue_time': 0.188946702, 'total_time': 0.061406289}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--fee86fb7-e337-4626-9791-a9aae95395c6-0', usage_metadata={'input_tokens': 28, 'output_tokens': 33, 'total_tokens': 61})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = { \"configurable\": { \"session_id\": \"user_session_4\" } }\n",
    "response = with_message_history.invoke({\"messages\": [HumanMessage(content=\"Hello, my name is mahdi\")], \"language\": \"French\"}, config=config)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e851bd6",
   "metadata": {},
   "source": [
    "# mamnaging history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50fad56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello, i am john and iam ai eng', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello ! its nice to meet you.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=' i like ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='i like ice cream too', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='i like chocolate', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='i like chocolate too', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='i like strawberry', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='i like strawberry too', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage , trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on='human'\n",
    "\n",
    ")\n",
    "messages = [\n",
    "        SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "        HumanMessage(content=\"Hello, i am john and iam ai eng\"),\n",
    "        AIMessage(content=\"Hello ! its nice to meet you.\"),\n",
    "        HumanMessage(content=\" i like ice cream\"),\n",
    "        AIMessage(content=\"i like ice cream too\"),\n",
    "        HumanMessage(content=\"i like chocolate\"),\n",
    "        AIMessage(content=\"i like chocolate too\"),\n",
    "        HumanMessage(content=\"i like strawberry\"),\n",
    "        AIMessage(content=\"i like strawberry too\")\n",
    "]\n",
    "\n",
    "\n",
    "trimmer.invoke(\n",
    "    messages\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bacde083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You like ice cream, chocolate, and strawberry! üç¶üç´üçì \\n\\nIs there anything else you'd like to tell me about what you like? üòä \\n\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter \n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
    "    | prompt \n",
    "    | model\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"messages\": messages + [HumanMessage(content=\"What i like ?\")] , \"language\": \"en\"})\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "557e14f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a helpful assistant, I don't have access to personal information like your name.  \\n\\nWould you like to tell me your name? üòä \\n\\n\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets add this to the messge history function\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain, \n",
    "    get_session_history,\n",
    "    input_messages_key= \"messages\"\n",
    ")\n",
    "config = {\"configurable\":{\"session_id\": \"user_session_5\"}}  # the session information\n",
    "\n",
    "response = with_message_history.invoke({\n",
    "    \"messages\": messages + [HumanMessage(content=\"What is my name ?\")] ,\n",
    "    \"language\": \"en\"\n",
    "}, config=config)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e6b02e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
